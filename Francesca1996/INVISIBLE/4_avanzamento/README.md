## Quarto avanzamento

Obiettivo --> Capire se utilizzare P5 speech o Sound Classifier <br>
Scomporre il progetto in piccole fasi e testare i codici.



1. Test P5 Speech
[+](https://editor.p5js.org/francy96/sketches/qQ9q8SDiP)
[+](https://editor.p5js.org/francy96/sketches/ATvOO6qNv)
[+](https://editor.p5js.org/francy96/sketches/hUZjHobey)

![the source](https://github.com/Francesca1996/archive/blob/master/Francesca1996/INVISIBLE/4_avanzamento/4_variazione.jpg)

<br>

2. Test Sound Classifier
[+](https://editor.p5js.org/francy96/sketches/gqoEryGaDr)

References
- Sound Classifier by Shiffman [+](https://www.youtube.com/watch?v=cO4UP2dX944)
- ml5 reference [+](https://ml5js.org/reference/api-soundClassifier/)
- Teachable Machine [+](https://teachablemachine.withgoogle.com/)
- Speech Command Recognizer [+](https://github.com/tensorflow/tfjs-models/tree/master/speech-commands)
- Sound Classification [+](https://dev.to/apoorvadave/environmental-sound-classification-1hhl)
- Sound Classification 2 [+](https://www.kdnuggets.com/2016/09/urban-sound-classification-neural-networks-tensorflow.html)

<br>

Appunti
- Capire come bloccare l’ascolto (se no disegna qualsiasi cosa o va in tilt); magari utilizzando un bottone, <br>
cosi decido io quando ascolta la mia voce.
- Prossimo step: collegare l’algoritmo che riconosce ciò che io dico a un’immagine. <br>
Se dico “cat” l’algoritmo mi disegnerà un gatto.

